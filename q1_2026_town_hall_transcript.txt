Speaker 1
So, today I'm going to be talking for, I'm setting my timer right now, about 25 to 30 minutes, about our plans for Q1 and also how we did on Q4. So we've been doing this quarterly roadmap for a year now. I love it. It's like, I think it's hopefully helps keep you all a little bit in tune with what we're doing, but also it's a great chance for us to make sure that we're staying like focused on our goals and that we're accountable for kind of what we said we were going to do last quarter and we're able to get it done. So today I will talk about specifically a Q4 retrospective, talk about what we did, talk about our 2026 strategy, because this is Q1. It's a good chance to just look at our strategy for the whole year. And boy, it's going to be a crazy year. So it's a good time for it. And then that turned to our Q1 roadmap specifically. And then we'll have, like I said, plenty of time for questions. So for Q4 retrospective, talking about our funder and awards coverage, we launched Walden, Revenue Bliss. I'm not going to read all these little individual ones. We'll do it like when we get there. Okay, so Q4 Retro. We had three main goals for Q4. We wanted to improve our coverage of funders and awards. And that was sort of the launch for stuff that was funded by the Welcome Trust. We announced that grant last year. And Q4 was the first quarter that we were able to make really solid progress towards the goals of that grant. The grant is online, so you can read it in its entirety, and we'll cover a little bit in a minute. Walden, which was the codename for our complete, full, total, soup-to-nuts rewrite of OpenAlex, moving it from the system that we launched with, which was very hacky because we needed to get it done real fast, to a modern system on Databricks that allowed us to improve our maintenance, ship new features faster, and just generally be way more responsive and actually make more progress. And then finally, revenue. We wanted to focus on making sure that we had good earned revenue to keep us sustainable. And we worked on a lot of stuff to try and learn about kind of how to improve our revenue. So let's take them one at a time. Let's talk about funders and awards. We created awards as a first-class entity. So now if you go to OpenAlex, you can look at OpenAlex slash awards. I'm not going to share right now because it'll take time. It's very straightforward, though. Go to OpenAlex and click on awards. And you'll see that we've got millions of awards that we've ingested into OpenAlex. Some of them are better metadata quality than others, more on that later, but they're there, which is amazing. And it's just a first class entity. And many of them are joined to the works that they fund, although not all of them, or even most of them. So we also started doing that join by linking from funder acknowledgement sections in works to the funders themselves. So if the work mentions, this work was funded by the National Institute of Health, then we're able to connect that to National Institute of Health. This is PDF parsing. We actually didn't, I don't think that was the PDFs. I think we got that from a different data source. The PDFs actually is coming up. I was a little bit of a confusing thing, sorry. But we extracted 27 million links from full text to funders. The goal here is that we're going to have the most complete database of funder to award links ever created. So every work, all of its funding from every funder. And eventually that also include the specific award numbers as well. That's the goal of what we're trying to do. So we made progress on that one. We also made progress integrating partners. So what I mean by that is we're adding the grants directly from the funders now. We added 15 new funders that were pulling, including a lot of the big ones. And we added more than a million awards from those funders. We're pulling that all directly from their websites, which is kind of an interesting job because everyone has their own format. So we go out, pull it in, we reconcile it into our format. That's going really fast. And we have very lofty goals for this coming quarter, which I'll touch on in a second. Okay, so that's the funder stuff, the Walden launch. Like I said, we wanted to migrate everything to Databricks, full rewrite, everybody says don't do that. There's a reason why they say don't do that. There was really no choice we had on this particular one, so I'm glad we did it. But boy, it was a slog. It took us all year, and we got it done, which was amazing. We added more than 170. This is a little out of date. It's going to be even more work than that. But we added more than 176 million new works. We have pushing 500 million. I think it'll be 470 before long. But we're pushing half a billion works. That makes us, I'm very proud to say, the largest repository of scholarly works connected together I think ever published, that anyone's ever had access to in history. That's really exciting. That's us trying to start living up to our namesake, the Library of Alexander. That's the dream is that we'll have, like I said, everything. We're getting there. So we added data site, added repositories. Those are very high requested features. Along the way, we were able to improve coverage of language and retractions. That was just kind of came for free along with the rewrite. Pretty happy about that. And we were able to add a bunch of institution affiliations. Honestly, that's a little bit of a work in progress. We're still missing some affiliations for some 24, 25 works. But we were able to fix a lot of those last quarter. We launched something called Oreo, the OpenAleks Rewrite Eval Overview. That got a pretty good response from the community. We were able to compare the old data set of OpenAleks, the legacy classic one, with the new one, the Walden one. And they were almost always the same or almost, yeah, generally the same or very close, which is great. Tricky to do with the rewrite. We wanted to launch a curation UI. We didn't get that done. That will launch early next month. More on that later. I was going to demo that here, but I think I'll demo that later. Our other big job along with Walden was we wanted to do this revenue blitz. So we wanted to learn a lot about how we can improve our earned revenue. That's really important for us because we want to be sustainable because that's a thing. So we moved snapshots from monthly to quarterly. That basically helps us keep our costs a little bit more in control. We are working on some premium features. We said last quarter we're going to work on these. We said we'd do vector search. That's not done. Probably it'll be Q1. PDF downloads, we said we're going to do that. So an endpoint where you can download the PDF straight from us. That's launching later this month. So within two weeks, didn't quite make it, but we're really close. And a better diff format. So a better way for API users to get what has changed in the API, in the data set for the last day. That's a paid feature. It works, but it's a little bit annoying on a technical side to work with. And so we were going to launch a better format. We did some research on that. I think it's going to take a little bit longer, but we'll get it done this quarter. We were looking into bespoke GUIs. So we would make a graphical user interface for someone for some money, and that would be a standalone. We're not going to do that. I think the GUI is dead. More on that later. And then some bonus achievements that we did that weren't on the roadmap. Everyone has an API key. If you log into OpenAlex, you can go to your settings and find your API key, which is cool. It's perfectly aligned with Unpayable now, so there's no difference between Unpayable and OpenAlex. And there was one other one that I forgot to write down, and that's you can download huge data sets now. So you can go and download actually a million row CSV if you want to on the Open. It takes 16 hours, but you can do it on the OpenAlex UI. it's very reliable. So that's what we did. All right, how are we trying? Doing okay. So let's look at our 2026 strategy. So I think everything changed this year. I've been excited about this since 2013. This is a paper I wrote talking about the web opens windows to disseminate scholarship as it happens. And then we're going to see a dramatic dieback in journals and a camera explosion of communication species. I think we're going to see that this year. We've already started to see in the back half of 2025. We're definitely going to see in 2026. Why? Because the tools are finally here. We actually are able to start cashing the checks that we wrote with Open Science. We said we're going to make all this stuff open, people will build amazing things on it, and they're really starting to build the amazing things. This is all of the different... I did an awesome... Claude Coe did a huge investigation on all of the different AI-powered tools that are building on Open Science right now. And I had like 150 examples of tools or something. I said, well, that's not very helpful. So we categorized them on. There's all these different categories. There are a lot of lists online now that you can use to look at these tools, but we are seeing that Cambrian explosion. So whatever you wanted to do in science, increasingly you're able to do because we have free intelligence on tap. Our view of 2026 and for our strategy and where we fit into this is to say that this world of open science and of open science powered tools has got three layers. It's got the ecosystem, the bedrock, and the soil, not in order. So the ecosystem is the one everyone's excited about, right? That's the top. That's all these tools that I just showed you, right? It's where the intelligence lives. Ecosystem requires intelligence. It's where the innovation lives, vibrancy, life. It used to be just journals, journals, journals, journals, right, I think of it as like a monoculture, like a tree farm or like a cornfield, right? It's all the same stuff. Now it's increasingly this messy, biodiverse, energetic rainforest. People are building all that stuff. All this stuff is going to replace journals over time. Not next year, but it is going to eventually replace journals. In the meantime, it's going to replace a lot of other tools that people were using as part of their scholarly workflows. the bedrock is necessary for the rainforest, obviously, right, for the ecosystem, right? It needs to be solid, dependable. It's a source of nutrients, right? That's where all the nutrients eventually come up to feed that ecosystem. And so we've had those and we've been working on those as a community for decades. So these are some of the, you know, CrossRef, Datasite, Orchid, amazing bedrock systems that everything is able to feed off of. But what's missing between those is soil, right? Trees can't grow straight out of bedrock. You can't have that. You need something that's homogenous, it's digestible. It's constantly available, it's always connected. That's where I think we fit in. I use the acronym ARIOS, all research information, one spot openly, a matrix for all of that biodiversity to grow out of. Something that's dependable is always going to be there. Something that digests all that bedrock because otherwise it's really hard to reach into all of those different services and connect them yourself. It takes a really long time. It tends to be hard to grow. So that's what we're doing. That's going to be kind of our big theme for 2026. Other big strategy themes that the GUIs did. What do I mean by that? I don't think people are going to do GUIs anymore. I think that that's increasingly, all we really need, right, is for this ecosystem, we need the intelligence and we need the soil for that to grow in. And then people just ask their own questions. So I thought I would do a couple demos of this and we do a little bit of vibing. So I don't know if you heard of this vibe coding idea. I think it's pretty funny word, it's very powerful so I'm going to try to stop sharing my screen and I'm going to try to share a different screen which is going to be at the very limits of my computer capabilities all right here it is so and now I'm going to you saw this prompt that we're going to use let's imagine that I have this question um and I want to graph AI papers so in the past I'm going to have logged into some commercial vendor, or maybe OpenAlex would have made something for me, I don't know. But now I can just ask this question. I want to graph AI papers from University of Florida versus University of Georgia. I'm a University of Florida alum, so I had to pick that one. And we're just going to use those years. And we'll use the OpenAlex API. So let's take a look at what it's doing. It's looking up the raw ideas and stuff. I find it useful to kind of view what the-- kind of what the trace is of what kind of work it's doing. So you kind of get a feel for like kind of the way it works. Looking up the IDs, that's great. And the key here is this is something that anybody can do, as you can see. So I wouldn't, if I would have like maybe the past logged into my SciVal or my Research Insights or whatever else, this is just, I don't think something anyone's going to do, but they're going to have an information need, right? And they need to connect with that information. Intelligence plus information equals knowledge. We've got the information. The intelligence is kind of on tap now. We can make knowledge with it together. A bespoke knowledge creation moment for everybody. So you can see that it's creating this chart. It's querying the Open Alex API. The important thing, right, is that information has to be accessible, and I'm happy to say that it is in Open Alex. And it's going to, I think, make us a little chart. All right, so it used these keywords for title search. Obviously, we have a lot of other ways that you could have done this. You could have done abstract search, you could have done full text, you could have done topics, lots of things. But I thought this was kind of a fun one. And yeah, you can see university, this is potentially a data quality issue would be kind of my guess that the university floor is bumping down there. But you can see it's like pretty significant growth. It's kind of what we expected. And this is something it's done. Yeah, we've got our chart, right? So the nice thing about this too, is we don't have this hallucination issue because this is coming straight from the OpenAlex API. And we can see that it's actually making those API calls. Okay, so here's the next one that I thought would be even cooler because I thought this is pretty neat to have a picture, but what if I could have an app? So we're going to put a new prompt in there and I can't see my whole screen because of the screen share thing. That's annoying. Let me see if, oh here we go. I'm gonna make a new chat. I'm going to paste this prompt. So let's take a second to read that prompt. Make me an app that works on a single local HTML page, no dependencies. It graphs work per year of different universities. Inspiration is Google Trends. I can pick up to eight unis. I can also narrow topic using title search. Obviously, use the OpenAleks API. When I click a data point, it shows... Oh, shows? Takes me. That doesn't make sense. It takes me to the OpenAleks website showing those works. All right, so this is going to take a minute. So what I'm going to do, I'm going to put that prompt in there, And then I'm going to share my screen to show you. I made it just right before the presentation. It takes about five minutes, and you can see this is kind of what it's doing. I'm going to go and now share my screen back to where I was. And okay, give me one second. I got to find my way. That's not it. Demo Vibco, okay. Okay, we're sharing the right screen. Now, let me just show you what it actually built for me. Again, it took about five minutes. And since we're like kind of pressed for time, I don't want to take the five minutes to just look at it. So here's what it built. So here's Harvard University. I'm going to filter. I don't want to do Harvard. Let's not do that one. I'm going to do University of Florida. Okay, so we do UF. This is just total papers because I haven't filtered yet. This is what came out of the system. I didn't do anything to this. I literally gave it that prompt and I let it cook for 10 minutes. So this is running on my local machine. You can see it's on my file system. Let's add, so let's compare Harvard. I think University of Florida is there, right? We're pretty much Harvard quality now. Oh, maybe not quite. So we can set our years and now let's see how they're doing in AI. This is just a title search and unsurprisingly kind of everybody's hockey's sticking there and let's do also we can separate a pipe I happen to know this would be something I would want to improve if I actually use it but artificial intelligence okay let's see if that gives us any oops that doesn't help any does it there we go so we start to see and we can add to that kind of search terms over time we can normally I didn't come up with this I think I just used it because it was from Google Trends. And we could keep adding universities like, you know, this is obviously not like the point of our conversation, but it's crazy that it could just build this. And then what I love is, because people always so worry about hallucinations, I think, right? So when I click on this, I can actually see the work, right? I go straight to the OpenAlex UI and I see these four in seven results. And of course I can view that in the API as well. So to me in that world, It does not make sense for us to be building GUIs. What we need to be doing is building an open data source that everybody can use, that they can use to build their own GUIs. That literally took me 10 minutes of work. And that's something anybody could do. This isn't even clawed code. This isn't coding, it's just radio cloud. Okay, prompt is the app, is my point. I think that our agency frontier as scholars, it extends, right? That stuff we're able to manipulate, it extends, it gets bigger. We don't need that meteor. We don't need someone at UILand and a big company to say, here's the things you can do. And so we just decided what we want to do. the key is we need access to big tidy and open info and so let me talk a little bit what does that mean when big we need all of the works we need every work that there is millions millions is hundreds of millions we need hundreds of works that's that's what open office is trying to be it needs to be tidy it needs to be connected and trusted it needs to obviously be open or these tools can't use them and it needs to be sustainable so let's look at those kind of i'm going to kind of zoom through those because it's kind of obvious i just kind of talked about it um oh but in terms of our strategy, we're adding works all the time. We're going to be really focusing on adding lots of works. We're already the biggest in the world. We're going to keep pushing on that. In terms of tidy, it means we need to be connected, duplicated, trusted. This is where we need the most improvement. We're going to do this in kind of two ways. We've already kind of got some automated agents that are trying to build, improve our data quality. We're going to really push in that direction. And we'll be working with the community to do curation. We're always been open, but we're going to start prioritizing agent experience, right? So letting agents easily consume the OpenOx API, just the way that I just did. And of course, we need to be sustainable. That's going to be super important. The stakes are, if we want open science, we got to pay for it, right? We got to work together on this. Otherwise, eventually, a for-profit can come and do it for us, which we do not want, because that sets the norms, right? That sets the, whatever the future looks like, it looks like their future. And I want it to look like our future, the future of those of us who care about open, who care about kind of the norms and the ideas behind research. So Q1 roadmap, we're going to zoom through this pretty quick, because I focused a lot on the coming year. We're going to keep working on the Wellcome project to improve funder and awards coverage. We're going to ingest awards from the top 100 funders. We should have 100 funders pretty soon. And we're going to keep building the funder community, including an in-person meeting. We're going to be working on features for enterprise. Better sync service. We already were supposed to do that last quarter, but we're going to try and get that done this quarter. We're going to add two new endpoints. Again, that was supposed to be last quarter. So we kind of already talked about that. We are looking for launch partners for Vector Search in particular. If you want a vector search, please let us know because it's kind of expensive and we need people. If we're going to prioritize it, we need people to show us that there's some actual money they're willing to pay for it. Otherwise, it's going to kind of keep being slow to implement. We're going to start doing credit based pricing. That's probably one of the biggest changes. It's not going to be by call. It's going to be by API. I announced this on the user list. Sorry, not by call, by credit. There'll be different credits for different types of API calls, which I'll show you in a second. The idea here is that different API calls cost us a different amount of money, and so we shouldn't treat them all as other homogenous. They're not. Specifically, this is very, very rough. We have not set a final price on these, but it's going to be something along the lines of a singleton. If you want one work, one credit. You want a list of work, 10 credits. Content, which is like download a PDF, is 100 credits, and vector is 1,000 credits. Very roughly, 10,000 credits is $1, and you can kind of do some of the math on some of the other products we're already selling fits in. We're going to offer API subscriptions, still definitely working on exactly how that looks. Keep getting free daily credits, although probably fewer than people get now. We'll have this pro tier, which could be maybe for well-funded individuals or less well-funded organizations. And we'll have this enterprise tier, which is pretty similar to what we already have. We'll also sell this data sync kind of separately as like a five to 10k year subscription. And then And finally, you can buy just like a pack of credits for particularly useful people who want to download like 50 million PDFs all in one shot. And then let's look at features that we do for government and education. So we kind of split them into these three areas, right? Like enterprise, sorry, welcome, which is basically a big grant we're doing, funders, then enterprise and government education. This is, I think, the one that I'm like most excited about. It's almost ready. You can edit the algorithm that OpenAlex uses to match affiliations. So what do I mean by that? going to show you what I mean. So here we are. We are doing so many live demos and a lot of guys have smiled on us so far. Okay, let's look at affiliation. I am currently viewing as Juan Pablo. Thank you, Juan, for letting me use your, to impersonate you, who's an admin at Simon Fraser University. And I want all of the content at Simon Fraser University to be correctly attributed to my institution. So the way I do that is, let me go back for a sec, and let's look at all of the affiliation strings in the database, this takes a little while because it's like millions, that are not linked to Simon Fraser University. So I can do that by, okay that's 118 million of these affiliations right. Now I want to see of the ones that are not linked to me, which ones do say Simon Fraser. So this is one that for whatever reason Open Alex is not correctly attributing to Simon. So I would just tick this and I would say match this to our institution and that'll match that one and anytime it ever sees that it'll match it. Some of these of course are really weird and so they would be so there's a manual component. After you submit those it's going to take one day and then you will see them right away in the API that will reflect it in our API and the data set and snapshots for everybody for all time. And then like I said you can kind of play with it. So you can say Simon, let's see if someone misspelled it maybe. Did I guess Simon Frasier. Yes, these porsels misspelled it. So I say I want to include that too, right? And of course, you can also see the ones that are correctly linked to us. And us here is Simon Frasier, because I'm like, I'm logged in. So let's look at the one. So we actually are getting some of these right. So let's say Simon Frasier. So Simon Frasier. All right, so Simon Frasier. So these ones, right, we are getting because it's got that little link thing. And if I wanted to unlink that, well, well, this isn't really us, click this and click on match. So that's kind of how that works. Obviously, that's a like super whirlwind tour and we'll kind of get more into it when we launch it. We'll have a video and stuff. So that was a demo. We're going to work on author name disambiguation. I think that's probably the hardest job in this space, always has been. But I think with today's tech, with AI, we can actually build the best ones ever been built and that's what we're going to do. That'll probably launch towards the end of the quarter. And we're going to just really focus on data quality. Like now that we have the wall in the system, it allows us to really iterate more quickly on data quality get a lot more progress a lot more quickly. And that's what we're going to do. We are going to launch some membership deals, which is pretty exciting. We're still working on this. The details are a little bit fuzzy, but I can tell you this part is pretty solid. We are going to launch a 5k member. It's going to be 5k a year. You can curate your affiliation stream matching, which I just showed. That's going to be a paid service. It costs us money to implement, costs us money to do the curations. We're looking for people who are going to be partners with us in making OpenAlex a better data set, right? That's kind of what we want to look at. And as a partner, I think we want people to help support like the goal that we're doing, both in terms of curation effort and in terms of like monetary support. So that's kind of the thinking behind it is that we're kind of all working on this together. It allows you to curate your affiliation string as I just showed you. So it gives you access to that tool and the dashboard and everything else. And it also gives you an unsub subscription. We're going to throw that in there, $3,000 value. Pretty cool. And it lets you go, gets you admission into a members roundtable. We'll be having like either monthly or quarterly meetings just for members because folks who are basically like buying into this community, both literally and figuratively. And so that's important to us. We're always going to try and listen to both free and paid users, but we need to obviously wait the folks who are putting their money where their mouth is a little bit more. And nominee advisory board members. So it kind of gives you an indirect say on the advisory board. And then we'll have a 20,000 member tier. $20,000 member tier. So that's everything in the 5K. Plus, you get these power user API keys. So you can distribute these to people at your university or your organization who need huge amounts of use, right? Use that would normally cost a lot of money. You get these five, and you can kind of distribute it to who you want. You're going to get dashboards for user management and for tracking your repository. That's my timer. And for tracking your repository ingest. I got four minutes. You get five hours of training consulting with us. I think that's probably the one that people have indicated is the highest value for them. any email support. We're thinking also of maybe having an in-between tier, like between the five and the 20, probably 10K. I'm interested in that too. These are both active right now. Like these are currently offered. So if you're interested in this, get in touch with us. Let's help support what we're doing here. And then finally, we'll have the government consortium tier, also active right now. And it's everything the other ones do, plus you get custom feature development, something small, but, and probably like kind of one small feature a year, but that's kind of what we've been doing with some of our government and consortium partners. so this is the year i i really think this is the most exciting and this is the i have been kind of building towards my whole open science career when i've been saying eventually people can build tools on this stuff i'm going to change the world that's going to happen this year like you know based on my use of these tools right now and just just you know kind of what we've seen even in the talk all this stuff is going to happen this year it's going to be massive and it's our really it's really our chance to kind of steer towards the open future we want and away from the closed future that we don't want. People say that, you know, the web, you know, it was so open, partly because it took commerce a long time to figure out what to do with it. And so there are always these, already these norms around openness on the web, around open standards, open URL standards, open domain standards, like that. I think that's great. Unfortunately, none of that really landed for scholarly communication, even though the web was built for scholarly communication at CERN. This is our chance, you know, kind of the thing that comes after the web, this kind of mesh of of ecosystems, right, of intelligence connected to information, that kind of three strata world of knowledge. Like we're kind of building the next generation that comes after the web. And I think we have a really big chance this year to set the default to open, as Spark like to say. I love that phrase, set the default to open. But we got to show real progress. We got to show that we're building something. We got to show we're building a community and we're building the data and the infrastructure to make it happen. So that's something I'm really excited about this year, really excited about this quarter. And I think with that, I got some little catchphrases here that I guess I was going to say. They're kind of cute. And I like connection, not constriction. I think we're done. I'd love to hear your questions. And I think, Kyle, if you don't mind, like, moderating the questions, that is generally really helpful for me because I can't concentrate on the little panel and listen and answer questions at the same time.

Speaker 2
Yeah, sure. Happy to. Thank you for the presentation. And just a reminder to everyone, the recording will be available. We can make the slides available as well. We have lots of questions, so let's go ahead and dive in. There was a question early on when you talked about the bulk download in the user interface that now does million publications. Is that also available through the API or is it just through the user interface?

Speaker 1
It's just the user interface right now because the idea is you create a job and then it just basically like checks the job for you like every couple of minutes for like hours and hours and hours on end. And we don't have like a kind of a way to do that in the API right now. We could launch it if people are interested. That could be an option. I think, yeah, that could be an option. People who want that in the API, let us know. Like I said, it's an async job, so you need to check on it yourself. But yeah, let us know if that's compelling to you. We can make it happen.

Speaker 2
Okay, great. There's a question about Walden and some of the metadata changes associated with it, specifically around works with more than 100 authors. There seems to be authors missing on those works. Is there a possibility to get all the authors from a work for these?

Speaker 1
Yes, for sure. Yeah, we basically chopped it off at 100 as part of the launch process. And then the plan that was supposed to get widened before we launched, but it didn't happen. So yeah, that's a very small number of works. But yeah, absolutely. We need to get all those authors in there. I think it might be in the snapshot that is launching today or tomorrow. If not, it'll be in the next snapshot.

Speaker 2
Okay, good. There's another question that is long and actually has two questions in it. The first is, what's the current status of the author profile curation request management? And you did talk about a new A&D system this quarter, but maybe you could briefly touch on that, and then I'll ask the second part.

Speaker 1
Yeah, it is somnolent. It's not working. It will wait. We started to implement that, and then we just kind of realized this is really so tightly integrated into the author name disambiguation, it doesn't make sense to launch one without the other. So it'll launch with the A&D. To me, I look at it as like a non-negotiable feature of the author name disambiguation, which I will often abbreviate A&D. Because it's going to like, no matter how good the algorithm is, and I think we're going to have the best ever. Like that's the goal. I think that's very doable in 2026. But there's always going to be mistakes and people need to be able to like curate those. So yeah, they'll be launched together. And you don't need to, you don't of course need to pay anything to like curate your own author profile, right? Like, I think people's data belongs to them. And so like, if they need to curate themselves, obviously they'll, they'll be going to do that for free.

Speaker 2
Yeah, great. And the second part of that question is on affiliation metadata. They've done a large analysis noticing a drop in affiliation metadata in 2024, 2025. This was after you sort of touched on it briefly. So maybe you can talk about the most recent work we just did on this.

Speaker 1
Yeah, yeah, we had a bug in that. We found the bug as a course of moving to Walden and we're fixing the buck. It's about half fixed right now. So the drop is not as pronounced as it was before, but it's only about half fixed, particularly affected are articles from Elsevier. And that is no shade on them. That's not like their fault. They're not like trying to hold us back or they just happened to be Elsevier. And yeah, we're working on it and we'll keep working on that till it's fixed. It's pretty important, obviously. particularly since its recent years. So I would expect that I kind of put that in the data quality section that we looked at. So that will be fixed by the end of the quarter for sure. I think within a month, more likely.

Speaker 2
And Ivan, I'll just add to that, that I think last week we pushed close to 2 million works in the last three years now have affiliations that didn't the week before. So we've already made significant progress on that that you should be able to see in the API and user interface. A couple of questions from when you were doing the vibe coding. Can you paste the prompts here? And then when you're doing the vibe coding, are you looking at differences between Claude and other AI chatbots?

Speaker 1
Yes and yes. Let me paste the prompts first. Where's the like?

Speaker 2
There's a chat that you should probably put it in.

Speaker 1
I do not understand how confused it works at all. I'm finding it now. I stopped sharing my screen and then it became easier. Chat. Yeah, and a reminder to everyone,

Speaker 2
that was sort of a teaser of a session we have coming up on January 29th. I put the registration in there where Jason's going to spend a lot more time showing the potential of Vibe Coding and how to do it a little bit more.

Speaker 1
Yes, and I really think, like I said, it's not an incidental thing to what OpenAlecs does or what OpenAlecs is. Like what we've always said is we're going to make all the world's research information open to everybody. And in that world, it's going to become very powerful. And I think it is a thousand times more powerful in 2026 than it was in 2025. Because you can actually do stuff with that information yourself. You're not limited, again, by someone with a UI and their opinion about how an app ought to work. So those are the two prompts. Your mileage may vary. There's definitely like, I would recommend if you're going to get deep into it, to use a tool called Claude Code, which is more code oriented. I will talk about that in the Vibe. I would love to get as many people that vibe coding thing as possible because I really think it's going to be big. I think eventually everybody who's building, a lot of the people, a lot of the people building UIs for scholarly communication, including a lot of incumbents in there, like not particularly calling me out, but like your Google scholars and your Scorpuses and your Web of Science and a lot of those folks. I think basically AI is just going to do an end run around all of that because no one is going to want to work with those UIs and try and figure out how they work when they could just build their own in 10 minutes. Or if they don't want to build their own UI, just ask their question and get an answer. Now, like I said, the great thing about OpenAlex, that makes it impossible kind of for those more traditional total access vendors to follow is like, we can show your work. So there's always going to be words about hallucinations, stuff like that. And click the thing, see the works. It's always right there behind it. And that's why Open, I've always felt, is it's not a liability. That's a selling point for us. And that's the future. So yeah, that's a bit of a discursive going. But yeah, those are the prompts. play with them have fun um and yeah let me let me know what you find the tools are all so new right now so there's a lot of sharp edges it's really easy to build something just doesn't work at all um but i i didn't like cheat on those prompts like those were like pretty much the first time i asked those prompts that's what i got so most it works a lot sometimes it doesn't

Speaker 2
yeah great and then there's a couple questions on the similar vein of to what degree is vibe coding being used to create Walden and to focus on data quality? How are we ensuring data quality of the core system in this space? And maybe you could talk about that. Yeah, honestly, as much as

Speaker 1
we can, you know, and I think people hear that and it kind of scares me. Like, well, like, dang, are you just like YOLOing like code that you've never read into the system and hoping that it works out? Like quite the opposite. Like what's amazing is that all like a lot of these vibe coding tools by adding intelligence into the process are allowed to find are helping us find so many errors so they're smart enough to look through and say where are the inconsistencies in this data and then of course that it flags it for manual inspection we look at it and then we can quickly write code that solves those problems and make automated tests that make sure they don't come back so to me the future uh is extremely bright about how how much vibe coding and you know i think agentic development is the one that people are going to try to sell because no one would buy vibe coding, that sounds horrifying, but I'm not easily terrified. But agent development slash vibe coding, I think that's all that is going to help us so much because like I said, we're going to be building all of those automated testing tools that flag things up for manual inspection and that we can use our knowledge of the domain, which at this point hopefully is some after doing this for 10 plus years, to integrate what we learned from the agents into Open Alex.

Speaker 2
And maybe I'll add something to that, that two use cases. The first is I got a support ticket yesterday on a bug in the user interface. And it was one that I was able to create a code to rapidly fix, whereas it normally used to have to go through a prioritization queue and take a long time. But you can see in the GitHub the change that was made, and it does say Kyle and Claude. So you can start to look at the contributors to the code and how that's happening. But taking a step back, one of the big purposes for Walden was to make things more simple because the graph got so complicated that we couldn't even change things. And a big part of what we're trying to do now is make things really simple so that chat GPT can understand it, but also so that individuals can understand it and we can understand it better. And a lot of our work lately has been providing instructions to LLMs online when people are trying to interact with our data to make it easy. So we're also trying to think about that when we're doing our development work.

Speaker 1
And then it's a good segue to the question about models, because, yeah, I really don't want to show for Claude here. Like, I think that currently they're at the top of the Claude Opus 4.5 is in my estimation at the top of the heat when it comes to coding models. And I think most people would agree. But there's a lot of other proprietary models out there that are like delivering similar results. And I think encouragingly, there's like the open models are generally the six to 12 months behind, which is amazing. So huge kudos to open models. And definitely as soon as those deliver like sufficient performance, we will certainly be looking into switching to those. because I would weigh in the open models. And I think the great thing about that is, you know, there are models that you can run locally that can do most of what I showed you, probably 80% of the way there, of what I showed you on Cloud right now. And that can be running on your own machine. It's not sending it up to some proprietary vendor or whatever. And I think we're going to hit that in 2026. So you can have a potentially that completely open tool chain that brings all the intelligence and all the information in one place so you can create knowledge. I'm really excited about that.

Speaker 2
And there's on this vein, maybe a critical question of whether or not depending upon centralized coding models is still open.

Speaker 1
Yeah, yeah, I think that's a fair question. At this point, I would decisively say yes, because there actually aren't any of these models integrated into our pipeline. Our pipeline is all deterministic. So like these are stochastic models, right? Like you want that prompt, you're going to something a little different than what you got when I showed it to you. We don't want any of that, or at least we have here to for it, strenuously avoided getting any of that in the OpenAleks pipeline. And that will certainly be like the plan we move forward. Like it's all actual regular old fashioned code that runs one time. It does what you, what it does every time. So our source code is all like fully open and it tells you exactly what the app does and you want to fork it and create your own OpenAleks. You can absolutely do that. And it's going to run the same way as ours does. The way we create that source code is definitely changing. So I would say our development workflow increasingly has a dependency on AI. We can still do it the old fashioned way, I guess. Like we haven't like forgotten how, but I think over the years, probably people will. My guess is that eventually people, English, I think a lot of smart people, including, and I would agree, I wouldn't say agree, man, I don't know if I'm smart, but I would say a lot of smart people. And this person, in addition, would say the English is the new coding language. I think most code is going to get written in English. Now, I think I'm always kind of wanting to be on the forefront of stuff or whatever. I always want to be on the leading edge. Other people will take longer to get there. But having used the tools a lot over the last few months, it's for sure that's what's going to happen. But yeah, that's a bit orthogonal to the question, which is, do we have a dependency on these models? No, we don't. We have a dependency on good old-fashioned Python and code. But we are definitely moving a lot faster because of these models right now.

Speaker 2
then there's a couple questions sort of in the same idea of some of these new subscription tiers asking are we working with consortia to get yes please discount um will there be credit system applicable to users um using api use accessing the api using ai as demonstrated so yeah you would just tell it your key and then is there a funder subscription tier uh and are options for funders to add custom metadata to awards?

Speaker 1
Talk to us about the custom metadata because that's part of our welcome grant. And basically the grant is funding us to go talk to you and we'll come up with something together. So let's do that. That'd be great. Y'all would go, in terms of subscription tiers, you'd go in GovEDU because it's sort of a combination of, I guess, Gov and EDU. You have authority, but, and also do education stuff. But yeah, so yeah, you'd go in the GovEDU tier. does that answer both those questions is there stuff left unanswered?

Speaker 2
Yeah, I'll just add to that if you are a funder because it says anonymous I'm not sure who you are please email me Kyle at openalex.org Welcome has funded this project like I said so we don't need any resources from you at the moment to be able to ingest your grant metadata and we want to work with you to get it but obviously thanks Jason oh that's to host some panelists anyways

Speaker 1
I just told Kyle

Speaker 2
his own email address in our private chat kyle.openalex.org but the other thing i'll say on that is we do work with funders around the world and it's a little bit more complicated with the subscription because they want different things and need different things and so we have an individual conversation on what you need and what we can work together on um so answered live great answered live yeah kyle can you can you put

Speaker 1
that i don't i don't seem to have the ability to say this everybody can you yeah because i have that of the dropdown, but it doesn't say I'm locked off from everybody.

Speaker 2
Yeah, we just have a couple of minutes and there's still quite a few.

Speaker 1
Can you send those prompts to everyone? Because I can't do it.

Speaker 2
Yes, I, somebody in the chat and then in the Q&A, I pasted that as well.

Speaker 1
Lovely, thank you. Oh, I see.

Speaker 2
Okay, so there's a question while I do that. We're looking at OpenAlex's keywords as granular categorization. Are there any plans? Oh, right. The API, the endpoint is no longer working for keywords. So they're not able to use that. Is that something that will be changing soon?

Speaker 1
Yeah, it's not the highest priority. So I would say if you're using the aboutness endpoint, it's called for keywords, definitely like hit us up and let us know that's important to you. And if you have money to help like pay for that, then definitely let us know that, too, because like it's always been a little bit of an afterthought. It's not really even like, it's like, I didn't even mention in my talk, like it's not a big priority for us. But if it's important to people, then it can become a bigger priority. So we'll do it, but I can't tell you the timeline.

Speaker 2
There's a question, I think it's from Bianca. It's BMR Kramer asking about member provided affiliation curation, whether or not there will be a check involved in any sort of provenance indicator in the data. Or as another option, would membership be considered a proxy for trust?

Speaker 1
Yeah, the second one. I mean, like we'll flag records if they get like edited and then edited back and edited back, like kind of like Wikipedia. If you track the edit history, it's like controversial or whatever. I mean, we'll probably look into it. But like, yeah, I assume that like if we're working with a librarian at the University of such and such who paid $5,000 to be a member, I assume they're not like there to vandalize our database. But yeah, I mean, in the very unlikely event that happens, we would have ways of reverting the changes.

Speaker 2
And Bianca, I'll add, or BMR, I'll add, part of this is also training that I would be providing to people before using this feature. We did try and open up curation last quarter, and two-thirds of them were wrong because the people who were submitting it didn't understand. So we do want to provide some training. And then, of course, we can check afterwards. Good question.

Speaker 1
If we do run into trouble, it's, yeah, like, we'll pivot on that. Like, if we need to moderate, we'll moderate it. Yeah.

Speaker 2
Will curation corrections be made available as a discrete open data set? Because organizations like Roar would like to benefit from it.

Speaker 1
Yeah, good thought. Sure, yeah, we can do that.

Speaker 2
Are there mechanisms for subscribers to correct metadata via API or the interface?

Speaker 1
Right now, no. We have like some Google Forms. it's all like pretty like ad hoc. I don't want to say ad hoc. It's a bit janky, I'll say. And yeah, the goal is I want to like make all that automated. So the dream for me has always been like the Wikidata style or Wikipedia style editing workflow. So that's what we're shooting for. We have to kind of vet those a little bit more. You know, we won't just let anyone do it the way Wikipedia does. Just kind of the nature of our data set is a little different. But yeah, that's the dream. That's not like for this quarter, but we're trying to like get there by stages. So for this quarter, we'll have some kind of author curation. So, hey, this isn't, my name is Jason Preem, but I'm a different Jason Preem. Like get that out of my stuff or, hey, this is me, like bring that stuff in. You'll be able to do that. And that'll be like a self-serve, you know, GUI experience. And then also, we already talked a lot about the affiliation stuff. So those will both launch this quarter. And then, yeah, we'll just keep trying to make other stuff like increasingly tractable or like changeable for people.

Speaker 2
that's great we're just at time i see there's a couple questions on the snapshot the next one will be available in the next couple of days it's a little bit late uh there's a couple bugs in the last one we wanted to make sure we got fixed and some of these affiliation things we said we wanted to get in so look in the next couple days and then jason i'll give you the the last question

Speaker 1
maybe that we can get to is where did you get your awesome mug from from uh zazzle i made it myself yeah it's pretty cool it says open alex on it thank you very much for the nice question yeah

Speaker 2
okay thanks again everyone for for coming for the great engagement and questions sorry we weren't able to get to all of them you can follow up with me kyle at openalex.org if you had some questions you really um that were burning that you didn't get addressed and we'll be happy to get

Speaker 1
those to you thanks again for the presentation jason thanks make sure to come to the vibe

coding thing i think it's going to be we're going to melt faces i think it's crazy what you can do right now, number one. And number two, this will be posted online and share with people.

Cool. Thanks, everyone.

